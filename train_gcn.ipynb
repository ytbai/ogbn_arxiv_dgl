{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"train_gcn_colab.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyOrgiaN9xERNuJK8UasSytd"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"8WNT4WTSoRE5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614655745531,"user_tz":480,"elapsed":330,"user":{"displayName":"Yuntao Bai","photoUrl":"","userId":"04964593421178204953"}},"outputId":"b76f5505-a4dd-40d3-d3dc-31a9ecfcb6fc"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KjotEWYff3eM","executionInfo":{"status":"ok","timestamp":1614655746266,"user_tz":480,"elapsed":215,"user":{"displayName":"Yuntao Bai","photoUrl":"","userId":"04964593421178204953"}}},"source":["\r\n","#include this at the top of any notebook to provide the path from which libraries are imported\r\n","import sys, os\r\n","libraries_dir = \"/content/drive/MyDrive/libraries\"\r\n","if libraries_dir not in sys.path:\r\n","  sys.path.append(libraries_dir)\r\n","\r\n","base_dir = \"/content/drive/My Drive/Colab Notebooks/projects/ogbn_arxiv_dgl\"\r\n","if base_dir not in sys.path:\r\n","  sys.path.append(base_dir)\r\n","os.chdir(base_dir)"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"fwbuPtrTSuzf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614655751892,"user_tz":480,"elapsed":5248,"user":{"displayName":"Yuntao Bai","photoUrl":"","userId":"04964593421178204953"}},"outputId":"b0013fb5-ab89-42dc-b711-71ecd7446119"},"source":["import torch\r\n","from torch import nn\r\n","import numpy as np\r\n","\r\n","from data_factory import *\r\n","from model_factory import *\r\n","from evaluate import *"],"execution_count":3,"outputs":[{"output_type":"stream","text":["WARNING:root:The OGB package is out of date. Your version is 1.2.5, while the latest version is 1.2.6.\n","Using backend: pytorch\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"Hc7YBtXA94DG","executionInfo":{"status":"ok","timestamp":1614655755755,"user_tz":480,"elapsed":7994,"user":{"displayName":"Yuntao Bai","photoUrl":"","userId":"04964593421178204953"}}},"source":["# Load ogbn-arxiv dataset\r\n","# Store graph onto GPU device\r\n","# Save dataset in directory root\r\n","dataset_name = \"ogbn-arxiv\"\r\n","device = \"cuda:0\"\r\n","root = \"dataset/\"\r\n","data_factory = DataFactory(dataset_name, device, root)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"NqWThPWdgfby","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614655755757,"user_tz":480,"elapsed":6630,"user":{"displayName":"Yuntao Bai","photoUrl":"","userId":"04964593421178204953"}},"outputId":"2b787ca2-4128-47b5-faa0-fd8838d5ab05"},"source":["# Model hyperparameters\r\n","d_input = 128+40\r\n","d_hidden = 256\r\n","d_output = n_class = 40\r\n","n_layer = 3\r\n","n_head = 1\r\n","masked = True # Establish whether or not to include masked label features\r\n","\r\n","# Initialize an instance of the model\r\n","model = GCN(d_input, d_output, d_hidden, n_layer, n_head, masked).to(device)\r\n","model.masked = masked\r\n","# Register the model name and directory so that model_factory will save the best model to \"models_dir/name\" during training\r\n","model_factory = ModelFactory(model, models_dir=\"saved_models\", name=\"GCNMasked\")\r\n","\r\n","# This registers the training loss, valid metric, and test metric so that model_factory will save their values to disk during training\r\n","model_factory.add_loss_name(\"train\", mode=\"min\")\r\n","model_factory.add_loss_name(\"valid\", mode=\"max\")\r\n","model_factory.add_loss_name(\"test\", mode=\"max\")\r\n","\r\n","# Print number of model parameters\r\n","model_factory.print_num_params()"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Number of parameters (total): 449832\n","Number of parameters (requires grad): 449832\n","Number of parameters (no grad): 0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dkF5J8sYyinm","executionInfo":{"status":"ok","timestamp":1614655755758,"user_tz":480,"elapsed":5768,"user":{"displayName":"Yuntao Bai","photoUrl":"","userId":"04964593421178204953"}}},"source":["# Training hyperparameters\r\n","lr = 0.005 # learning rate\r\n","criterion = CrossEntropyLossSmooth # training loss\r\n","optimizer = torch.optim.Adam(model.parameters(), lr)\r\n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.1, patience=500, verbose=True)\r\n","\r\n","# This registers the optimizer and scheduler so that model_factory will save their state_dict to disk during training\r\n","model_factory.set_optimizer(optimizer)\r\n","model_factory.set_scheduler(scheduler)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9xBgHQAbg2xk","executionInfo":{"status":"ok","timestamp":1614657455473,"user_tz":480,"elapsed":1704666,"user":{"displayName":"Yuntao Bai","photoUrl":"","userId":"04964593421178204953"}},"outputId":"676c9dcd-d27f-4e73-e898-e88fc8a9250d"},"source":["epochs = 2000\r\n","log_every = 20\r\n","\r\n","for epoch in range(epochs):\r\n","  # Train for one epoch\r\n","  loss_train = train(model_factory, data_factory, criterion)\r\n","  # Store last training loss to memory\r\n","  model_factory.append_loss(\"train\", loss_train)\r\n","\r\n","  # Validate\r\n","  valid_score = evaluate(model_factory, data_factory, dataset_name, split_name=\"valid\")\r\n","  # Store last validation score to memory\r\n","  model_factory.append_loss(\"valid\", valid_score)\r\n","\r\n","  # Test\r\n","  test_score = evaluate(model_factory, data_factory, dataset_name, split_name=\"test\")\r\n","  # Store last test score to memory\r\n","  model_factory.append_loss(\"test\", test_score)\r\n","\r\n","  # After each epoch, store the training loss, validation score, test score, optimizer state_dict, and scheduler state_dict to disk\r\n","  # If validation score is best, then also save model state_dict to disk\r\n","  model_factory.save_best(\"valid\")\r\n","\r\n","  # Log results periodically\r\n","  if epoch%log_every==0:\r\n","    # Print results from current epoch\r\n","    model_factory.print_last_loss(epoch)\r\n","\r\n"],"execution_count":7,"outputs":[{"output_type":"stream","text":["epoch: 0 train 0.791914 valid 0.325615 test 0.291793 \n","best train 0.791914 best valid 0.325615 best test 0.291793  \n","epoch: 20 train 0.347259 valid 0.646263 test 0.634693 \n","best train 0.347259 best valid 0.646263 best test 0.634693  \n","epoch: 40 train 0.286574 valid 0.701332 test 0.680226 \n","best train 0.285883 best valid 0.701769 best test 0.687365  \n","epoch: 60 train 0.261968 valid 0.716702 test 0.691933 \n","best train 0.261968 best valid 0.718178 best test 0.705018  \n","epoch: 80 train 0.253079 valid 0.720830 test 0.697940 \n","best train 0.251838 best valid 0.727843 best test 0.712549  \n","epoch: 100 train 0.244770 valid 0.729286 test 0.711993 \n","best train 0.244770 best valid 0.735595 best test 0.721992  \n","epoch: 120 train 0.243000 valid 0.732911 test 0.716252 \n","best train 0.241510 best valid 0.735964 best test 0.723782  \n","epoch: 140 train 0.238099 valid 0.732206 test 0.708228 \n","best train 0.238041 best valid 0.737441 best test 0.723782  \n","epoch: 160 train 0.238177 valid 0.735595 test 0.715697 \n","best train 0.235763 best valid 0.739555 best test 0.724852  \n","epoch: 180 train 0.236035 valid 0.734454 test 0.713145 \n","best train 0.234810 best valid 0.739555 best test 0.724852  \n","epoch: 200 train 0.233544 valid 0.722944 test 0.694484 \n","best train 0.232296 best valid 0.740864 best test 0.724852  \n","epoch: 220 train 0.231854 valid 0.740025 test 0.720737 \n","best train 0.230494 best valid 0.741803 best test 0.726478  \n","epoch: 240 train 0.229377 valid 0.731266 test 0.702097 \n","best train 0.229377 best valid 0.741803 best test 0.726478  \n","epoch: 260 train 0.230397 valid 0.738515 test 0.717589 \n","best train 0.227143 best valid 0.743012 best test 0.726478  \n","epoch: 280 train 0.226407 valid 0.723044 test 0.695307 \n","best train 0.225339 best valid 0.743012 best test 0.728638  \n","epoch: 300 train 0.226374 valid 0.730662 test 0.710532 \n","best train 0.223680 best valid 0.743213 best test 0.728638  \n","epoch: 320 train 0.224512 valid 0.738078 test 0.716232 \n","best train 0.222974 best valid 0.743783 best test 0.730346  \n","epoch: 340 train 0.223830 valid 0.736837 test 0.714030 \n","best train 0.221812 best valid 0.743783 best test 0.730346  \n","epoch: 360 train 0.221159 valid 0.736401 test 0.715902 \n","best train 0.219797 best valid 0.743783 best test 0.730346  \n","epoch: 380 train 0.221014 valid 0.737005 test 0.714853 \n","best train 0.219797 best valid 0.743783 best test 0.730346  \n","epoch: 400 train 0.218386 valid 0.739152 test 0.718412 \n","best train 0.217959 best valid 0.744622 best test 0.730346  \n","epoch: 420 train 0.221994 valid 0.739119 test 0.725696 \n","best train 0.217623 best valid 0.744622 best test 0.730346  \n","epoch: 440 train 0.218881 valid 0.741669 test 0.722239 \n","best train 0.215217 best valid 0.744622 best test 0.730346  \n","epoch: 460 train 0.218603 valid 0.735092 test 0.715038 \n","best train 0.215132 best valid 0.744622 best test 0.730346  \n","epoch: 480 train 0.217274 valid 0.736199 test 0.710861 \n","best train 0.214500 best valid 0.744622 best test 0.730346  \n","epoch: 500 train 0.216879 valid 0.727474 test 0.698475 \n","best train 0.212479 best valid 0.744622 best test 0.730346  \n","epoch: 520 train 0.214200 valid 0.734387 test 0.707631 \n","best train 0.212479 best valid 0.744622 best test 0.730408  \n","epoch: 540 train 0.215368 valid 0.740293 test 0.725202 \n","best train 0.211081 best valid 0.744622 best test 0.730408  \n","epoch: 560 train 0.213649 valid 0.735159 test 0.710368 \n","best train 0.210986 best valid 0.744622 best test 0.732444  \n","epoch: 580 train 0.212956 valid 0.740226 test 0.724955 \n","best train 0.210757 best valid 0.744622 best test 0.732444  \n","epoch: 600 train 0.211633 valid 0.734051 test 0.710162 \n","best train 0.210131 best valid 0.744622 best test 0.732444  \n","epoch: 620 train 0.210879 valid 0.737172 test 0.710347 \n","best train 0.209703 best valid 0.744622 best test 0.732444  \n","epoch: 640 train 0.209854 valid 0.741334 test 0.720655 \n","best train 0.208541 best valid 0.744622 best test 0.732444  \n","epoch: 660 train 0.211097 valid 0.739052 test 0.723741 \n","best train 0.207521 best valid 0.744622 best test 0.732444  \n","epoch: 680 train 0.208666 valid 0.734219 test 0.714030 \n","best train 0.207521 best valid 0.744622 best test 0.732444  \n","epoch: 700 train 0.209422 valid 0.733078 test 0.709936 \n","best train 0.206938 best valid 0.744622 best test 0.732444  \n","epoch: 720 train 0.208501 valid 0.741434 test 0.730222 \n","best train 0.206938 best valid 0.744622 best test 0.732444  \n","epoch: 740 train 0.207195 valid 0.738615 test 0.720717 \n","best train 0.206938 best valid 0.744622 best test 0.732444  \n","epoch: 760 train 0.209473 valid 0.739723 test 0.723494 \n","best train 0.206729 best valid 0.744622 best test 0.732444  \n","epoch: 780 train 0.207458 valid 0.738078 test 0.715532 \n","best train 0.205798 best valid 0.744622 best test 0.732444  \n","epoch: 800 train 0.206012 valid 0.740528 test 0.722425 \n","best train 0.205298 best valid 0.744622 best test 0.732444  \n","epoch: 820 train 0.206249 valid 0.733951 test 0.709709 \n","best train 0.203497 best valid 0.744622 best test 0.732444  \n","epoch: 840 train 0.204304 valid 0.740025 test 0.725696 \n","best train 0.203497 best valid 0.744622 best test 0.732444  \n","epoch: 860 train 0.203689 valid 0.737743 test 0.720429 \n","best train 0.203497 best valid 0.744622 best test 0.732444  \n","epoch: 880 train 0.206500 valid 0.739756 test 0.720223 \n","best train 0.202883 best valid 0.744622 best test 0.732444  \n","epoch: 900 train 0.205957 valid 0.737139 test 0.712137 \n","best train 0.202883 best valid 0.744622 best test 0.732444  \n","epoch: 920 train 0.203062 valid 0.737407 test 0.714297 \n","best train 0.202202 best valid 0.744622 best test 0.732444  \n","epoch: 940 train 0.203302 valid 0.735058 test 0.706911 \n","best train 0.201822 best valid 0.744622 best test 0.732444  \n","epoch: 960 train 0.203722 valid 0.734790 test 0.709771 \n","best train 0.201822 best valid 0.744622 best test 0.732444  \n","epoch: 980 train 0.202915 valid 0.740428 test 0.722095 \n","best train 0.201822 best valid 0.744622 best test 0.732444  \n","epoch: 1000 train 0.203324 valid 0.736065 test 0.713145 \n","best train 0.199365 best valid 0.744622 best test 0.732444  \n","epoch: 1020 train 0.200354 valid 0.736166 test 0.712837 \n","best train 0.199365 best valid 0.744622 best test 0.732444  \n","epoch: 1040 train 0.200976 valid 0.740897 test 0.720799 \n","best train 0.198803 best valid 0.744622 best test 0.732444  \n","epoch: 1060 train 0.199660 valid 0.737709 test 0.715491 \n","best train 0.198803 best valid 0.744622 best test 0.732444  \n","epoch: 1080 train 0.201216 valid 0.733145 test 0.713845 \n","best train 0.198803 best valid 0.744622 best test 0.732444  \n","epoch: 1100 train 0.199061 valid 0.732944 test 0.706808 \n","best train 0.198803 best valid 0.744622 best test 0.732444  \n","epoch: 1120 train 0.201825 valid 0.738414 test 0.721499 \n","best train 0.198714 best valid 0.744622 best test 0.732444  \n","epoch: 1140 train 0.202134 valid 0.737474 test 0.717610 \n","best train 0.198714 best valid 0.744622 best test 0.732444  \n","epoch: 1160 train 0.201473 valid 0.739354 test 0.722342 \n","best train 0.198714 best valid 0.744622 best test 0.732444  \n","epoch: 1180 train 0.201221 valid 0.737374 test 0.713865 \n","best train 0.198475 best valid 0.744622 best test 0.732444  \n","epoch: 1200 train 0.200162 valid 0.731065 test 0.701726 \n","best train 0.197381 best valid 0.744622 best test 0.732444  \n","epoch: 1220 train 0.200103 valid 0.736501 test 0.717384 \n","best train 0.197381 best valid 0.744622 best test 0.732444  \n","epoch: 1240 train 0.199433 valid 0.738750 test 0.715532 \n","best train 0.197381 best valid 0.744622 best test 0.732444  \n","epoch: 1260 train 0.198347 valid 0.734588 test 0.712425 \n","best train 0.197381 best valid 0.744622 best test 0.732444  \n","epoch: 1280 train 0.198317 valid 0.731501 test 0.706150 \n","best train 0.197381 best valid 0.744622 best test 0.732444  \n","epoch: 1300 train 0.199860 valid 0.733313 test 0.708537 \n","best train 0.197381 best valid 0.744622 best test 0.732444  \n","epoch: 1320 train 0.199962 valid 0.737441 test 0.716581 \n","best train 0.197053 best valid 0.744622 best test 0.732444  \n","epoch: 1340 train 0.195819 valid 0.738347 test 0.715429 \n","best train 0.195819 best valid 0.744622 best test 0.732444  \n","epoch: 1360 train 0.198652 valid 0.739454 test 0.718351 \n","best train 0.195819 best valid 0.744622 best test 0.732444  \n","epoch: 1380 train 0.198564 valid 0.739219 test 0.714524 \n","best train 0.195819 best valid 0.744622 best test 0.732444  \n","epoch: 1400 train 0.197557 valid 0.740797 test 0.718454 \n","best train 0.195819 best valid 0.744622 best test 0.732444  \n","epoch: 1420 train 0.197807 valid 0.737542 test 0.721560 \n","best train 0.195819 best valid 0.744622 best test 0.732444  \n","epoch: 1440 train 0.198313 valid 0.733682 test 0.708351 \n","best train 0.195819 best valid 0.744622 best test 0.732444  \n","epoch: 1460 train 0.198829 valid 0.741199 test 0.723741 \n","best train 0.195674 best valid 0.744622 best test 0.732444  \n","epoch: 1480 train 0.198574 valid 0.731803 test 0.707590 \n","best train 0.195674 best valid 0.744622 best test 0.732444  \n","epoch: 1500 train 0.195109 valid 0.737508 test 0.713639 \n","best train 0.194020 best valid 0.744622 best test 0.732444  \n","epoch: 1520 train 0.197926 valid 0.737105 test 0.714195 \n","best train 0.194020 best valid 0.744622 best test 0.732444  \n","epoch: 1540 train 0.197503 valid 0.742877 test 0.724441 \n","best train 0.194020 best valid 0.744622 best test 0.732444  \n","epoch: 1560 train 0.196329 valid 0.739253 test 0.716643 \n","best train 0.194020 best valid 0.744622 best test 0.732444  \n","epoch: 1580 train 0.195898 valid 0.741468 test 0.719853 \n","best train 0.194020 best valid 0.744622 best test 0.732444  \n","epoch: 1600 train 0.195367 valid 0.728615 test 0.696583 \n","best train 0.194020 best valid 0.744622 best test 0.732444  \n","epoch: 1620 train 0.197498 valid 0.741636 test 0.723556 \n","best train 0.194020 best valid 0.744622 best test 0.732444  \n","epoch: 1640 train 0.196840 valid 0.737340 test 0.716149 \n","best train 0.194020 best valid 0.744622 best test 0.732444  \n","epoch: 1660 train 0.195985 valid 0.735394 test 0.710285 \n","best train 0.193726 best valid 0.744622 best test 0.732444  \n","epoch: 1680 train 0.195053 valid 0.737542 test 0.716520 \n","best train 0.193674 best valid 0.744622 best test 0.732444  \n","epoch: 1700 train 0.196866 valid 0.739589 test 0.722671 \n","best train 0.193674 best valid 0.744622 best test 0.732444  \n","epoch: 1720 train 0.197052 valid 0.738011 test 0.716828 \n","best train 0.193674 best valid 0.744622 best test 0.732444  \n","epoch: 1740 train 0.195398 valid 0.741199 test 0.718659 \n","best train 0.193674 best valid 0.744622 best test 0.732444  \n","epoch: 1760 train 0.195481 valid 0.739052 test 0.717836 \n","best train 0.192535 best valid 0.744622 best test 0.732444  \n","epoch: 1780 train 0.195245 valid 0.733749 test 0.708537 \n","best train 0.192513 best valid 0.744622 best test 0.732444  \n","epoch: 1800 train 0.196557 valid 0.736132 test 0.711973 \n","best train 0.192490 best valid 0.744622 best test 0.732444  \n","epoch: 1820 train 0.193250 valid 0.739488 test 0.718742 \n","best train 0.192402 best valid 0.744622 best test 0.732444  \n","epoch: 1840 train 0.194678 valid 0.734488 test 0.705286 \n","best train 0.191167 best valid 0.744622 best test 0.732444  \n","epoch: 1860 train 0.195557 valid 0.735830 test 0.711931 \n","best train 0.191167 best valid 0.744622 best test 0.732444  \n","epoch: 1880 train 0.195319 valid 0.736367 test 0.709874 \n","best train 0.191167 best valid 0.744622 best test 0.732444  \n","epoch: 1900 train 0.194032 valid 0.732508 test 0.703310 \n","best train 0.191167 best valid 0.744824 best test 0.732444  \n","epoch: 1920 train 0.194122 valid 0.739622 test 0.714709 \n","best train 0.191167 best valid 0.744824 best test 0.732444  \n","epoch: 1940 train 0.192502 valid 0.735998 test 0.711849 \n","best train 0.191167 best valid 0.744824 best test 0.732444  \n","epoch: 1960 train 0.193608 valid 0.737374 test 0.715573 \n","best train 0.190802 best valid 0.744824 best test 0.732444  \n","epoch: 1980 train 0.193304 valid 0.733682 test 0.705574 \n","best train 0.190802 best valid 0.744824 best test 0.732444  \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XnsDbs15hz7n"},"source":[""],"execution_count":null,"outputs":[]}]}